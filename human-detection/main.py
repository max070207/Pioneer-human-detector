# main.py
import cv2
import numpy as np
import time
from camera_controller import CameraController
from pose_detector import PoseDetector
from face_recognizer import FaceRecognizer
from file_manager import FileManager

class HumanDetector:
    def __init__(self):
        self.file_manager = FileManager()
        self.camera = CameraController()
        self.pose_detector = PoseDetector()
        self.face_recognizer = FaceRecognizer(self.file_manager)
        
        # –°–æ—Å—Ç–æ—è–Ω–∏–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è
        self.previous_human_detected = False
        self.current_human_detected = False
        self.face_tracking_active = False  # –§–ª–∞–≥ –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ª–∏—Ü
        self.tracked_faces = set()  # –ú–Ω–æ–∂–µ—Å—Ç–≤–æ —É–∂–µ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º—ã—Ö –ª–∏—Ü

    def update_detection_status(self, human_detected, frame):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è"""
        self.current_human_detected = human_detected

        if self.current_human_detected != self.previous_human_detected:
            if self.current_human_detected:
                print("‚úÖ —á–µ–ª–æ–≤–µ–∫ –æ–±–Ω–∞—Ä—É–∂–µ–Ω")
                self.file_manager.save_human_photo(frame)
                # –ê–∫—Ç–∏–≤–∏—Ä—É–µ–º –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ª–∏—Ü –ø–æ—Å–ª–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è —á–µ–ª–æ–≤–µ–∫–∞
                self.face_tracking_active = True
                print("üë§ –ê–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–æ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ª–∏—Ü")
            else:
                print("‚ùå —á–µ–ª–æ–≤–µ–∫ –ø–æ—Ç–µ—Ä—è–Ω")
                # –î–µ–∞–∫—Ç–∏–≤–∏—Ä—É–µ–º –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ª–∏—Ü
                self.face_tracking_active = False
                self.tracked_faces.clear()  # –û—á–∏—â–∞–µ–º —Å–ø–∏—Å–æ–∫ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º—ã—Ö –ª–∏—Ü
                print("üë§ –î–µ–∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–æ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ª–∏—Ü")

            self.previous_human_detected = self.current_human_detected

    def show_camera_feed(self):
        """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –æ–∫–Ω–∞ —Å –∫–∞–º–µ—Ä–æ–π –¥—Ä–æ–Ω–∞"""
        if not self.camera.drone_connected:
            print("‚ö†Ô∏è  –†–∞–±–æ—Ç–∞ –≤ —Ä–µ–∂–∏–º–µ —Å–∏–º—É–ª—è—Ü–∏–∏ (–¥—Ä–æ–Ω –Ω–µ –ø–æ–¥–∫–ª—é—á–µ–Ω)")

        print("üöÅ –ó–∞–ø—É—Å–∫ —Å–∏—Å—Ç–µ–º—ã –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è —á–µ–ª–æ–≤–µ–∫–∞ —Å –∫–∞–º–µ—Ä—ã –¥—Ä–æ–Ω–∞...")
        print("üë§ –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ª–∏—Ü –∞–∫—Ç–∏–≤–∏—Ä—É–µ—Ç—Å—è –ø–æ—Å–ª–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è —á–µ–ª–æ–≤–µ–∫–∞")
        print("–î–ª—è –≤—ã—Ö–æ–¥–∞ –Ω–∞–∂–º–∏—Ç–µ 'q' –≤ –æ–∫–Ω–µ –≤–∏–¥–µ–æ")

        frame_count = 0

        while True:
            ret, raw_frame = self.camera.get_frame()

            if not ret:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–∞–¥—Ä–∞ {frame_count}")
                frame = np.zeros((480, 640, 3), dtype=np.uint8)
                cv2.putText(frame, "DRONE CAMERA ERROR - NO VIDEO FEED", (80, 240),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            else:
                # –ö–û–ü–ò–Ø –∫–∞–¥—Ä–∞ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è (–±—É–¥–µ—Ç —Å —Å–∫–µ–ª–µ—Ç–æ–º –∏ –ª–∏—Ü–∞–º–∏)
                display_frame = raw_frame.copy()

                # 1. –û–ë–ù–ê–†–£–ñ–ï–ù–ò–ï –°–ö–ï–õ–ï–¢–ê –ò –û–¢–†–ò–°–û–í–ö–ê
                human_detected_in_frame, display_frame = self.pose_detector.detect_and_draw(display_frame)

                # 2. –û–¢–°–õ–ï–ñ–ò–í–ê–ù–ò–ï –õ–ò–¶ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω —á–µ–ª–æ–≤–µ–∫)
                recognized_persons = []
                if self.face_tracking_active:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —á–∏—Å—Ç—ã–π –∫–∞–¥—Ä –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –ª–∏—Ü
                    recognized_persons = self.face_recognizer.detect_and_track_faces(
                        raw_frame, 
                        self.tracked_faces
                    )
                    
                    # 3. –û–¢–†–ò–°–û–í–ö–ê –õ–ò–¶
                    display_frame = self.face_recognizer.draw_faces(display_frame, recognized_persons)

                # 4. –ê–Ω–∞–ª–∏–∑ —Å–æ—Å—Ç–æ—è–Ω–∏—è –¥–ª—è –≤—ã–≤–æ–¥–∞ –≤ –∫–æ–Ω—Å–æ–ª—å
                if frame_count % 30 == 0:
                    self.update_detection_status(human_detected_in_frame, raw_frame)

                # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
                self.add_info_text(display_frame, human_detected_in_frame, frame_count, recognized_persons)

                frame = display_frame

            window_name = 'üöÅ –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —á–µ–ª–æ–≤–µ–∫–∞ –∏ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ª–∏—Ü - –ö–∞–º–µ—Ä–∞ –¥—Ä–æ–Ω–∞'
            cv2.imshow(window_name, frame)

            frame_count += 1

            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

        self.cleanup()

    def add_info_text(self, frame, human_detected, frame_count, recognized_persons):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –∫–∞–¥—Ä"""
        status_text = "HUMAN DETECTED" if human_detected else "HUMAN NOT DETECTED"
        color = (0, 255, 0) if human_detected else (0, 0, 255)

        cv2.putText(frame, status_text, (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)

        # –°—Ç–∞—Ç—É—Å –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ª–∏—Ü
        tracking_status = "FACE TRACKING: ACTIVE" if self.face_tracking_active else "FACE TRACKING: INACTIVE"
        tracking_color = (0, 255, 0) if self.face_tracking_active else (0, 0, 255)
        cv2.putText(frame, tracking_status, (10, 60),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, tracking_color, 2)

        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–∞–º–µ—Ä–µ
        if self.camera.current_camera_type == "DRONE":
            camera_status = "DRONE CAMERA - CONNECTED"
            camera_color = (0, 255, 0)
        elif self.camera.current_camera_type == "LAPTOP":
            camera_status = "LAPTOP CAMERA - ACTIVE"
            camera_color = (0, 255, 255)  # –ñ–µ–ª—Ç—ã–π –¥–ª—è –∫–∞–º–µ—Ä—ã –Ω–æ—É—Ç–±—É–∫–∞
        else:
            camera_status = "SIMULATION MODE"
            camera_color = (0, 165, 255)  # –û—Ä–∞–Ω–∂–µ–≤—ã–π –¥–ª—è —Å–∏–º—É–ª—è—Ü–∏–∏

        cv2.putText(frame, f"CAMERA: {camera_status}", (10, 90),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, camera_color, 2)

        cv2.putText(frame, f"FRAME: {frame_count}", (10, 120),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
        if self.face_tracking_active:
            recognized_count = len([p for p in recognized_persons if p[0] != "Unknown"])
            faces_text = f"TRACKED FACES: {len(recognized_persons)} (KNOWN: {recognized_count})"
            cv2.putText(frame, faces_text, (10, 140),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)

            tracked_count = f"UNIQUE FACES: {len(self.tracked_faces)}"
            cv2.putText(frame, tracked_count, (10, 160),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)

    def cleanup(self):
        """–û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤"""
        self.camera.cleanup()
        self.pose_detector.cleanup()
        cv2.destroyAllWindows()
        print("‚úÖ –†–µ—Å—É—Ä—Å—ã –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω—ã")
        print(f"üìÅ –°–Ω–∏–º–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {self.file_manager.photos_folder}")
        print(f"üìÅ –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–µ –ª–∏—Ü–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {self.file_manager.faces_folder}")
        print(f"üë§ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ª–∏—Ü –æ—Ç—Å–ª–µ–∂–µ–Ω–æ: {len(self.tracked_faces)}")


# –ó–∞–ø—É—Å–∫ —Å–∏—Å—Ç–µ–º—ã
if __name__ == "__main__":
    detector = HumanDetector()
    detector.show_camera_feed()