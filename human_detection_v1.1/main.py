# main.py
from imports import *
from camera_controller import CameraController
from pose_detector import PoseDetector
from face_recognizer import FaceRecognizer
from file_manager import FileManager

class HumanDetector:
    def __init__(self):
        self.file_manager = FileManager()
        self.camera = CameraController()
        self.pose_detector = PoseDetector()
        self.face_recognizer = FaceRecognizer(self.file_manager)
        
        # –°–æ—Å—Ç–æ—è–Ω–∏–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è
        self.previous_human_detected = False
        self.current_human_detected = False
        self.face_tracking_active = False
        self.tracked_faces = set()
        
        # FPS —Å—á–µ—Ç—á–∏–∫
        self.frame_count = 0
        self.last_fps_time = time.time()
        self.fps = 0

    def update_detection_status(self, human_detected, frame):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è"""
        self.current_human_detected = human_detected

        if self.current_human_detected != self.previous_human_detected:
            if self.current_human_detected:
                print("‚úÖ —á–µ–ª–æ–≤–µ–∫ –æ–±–Ω–∞—Ä—É–∂–µ–Ω")
                self.file_manager.save_human_photo(frame)
                self.face_tracking_active = True
                print("üë§ –ê–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–æ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ª–∏—Ü")
            else:
                print("‚ùå —á–µ–ª–æ–≤–µ–∫ –ø–æ—Ç–µ—Ä—è–Ω")
                self.face_tracking_active = False
                self.tracked_faces.clear()
                print("üë§ –î–µ–∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–æ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ª–∏—Ü")

            self.previous_human_detected = self.current_human_detected

    def show_camera_feed(self):
        """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ª–∏—Ü –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–∏"""
        print("üöÅ –ó–∞–ø—É—Å–∫ —Å–∏—Å—Ç–µ–º—ã —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ª–∏—Ü –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–∏...")
        print("üíæ –ö–∞–∂–¥–æ–µ –Ω–æ–≤–æ–µ –ª–∏—Ü–æ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –æ–¥–∏–Ω —Ä–∞–∑ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏–∏")
        
        fps_counter = 0
        last_fps_calc = time.time()

        while True:
            frame_start = time.time()
            fps_counter += 1
            
            # –ü–æ–ª—É—á–µ–Ω–∏–µ –∫–∞–¥—Ä–∞
            ret, raw_frame = self.camera.get_frame()

            if not ret:
                continue
            
            display_frame = raw_frame.copy()

            # 1. –ê–°–ò–ù–•–†–û–ù–ù–û–ï –û–ë–ù–ê–†–£–ñ–ï–ù–ò–ï –°–ö–ï–õ–ï–¢–ê
            human_detected_in_frame, display_frame = self.pose_detector.detect_and_draw_async(
                display_frame, self.frame_count
            )

            # 2. –ü–û–°–¢–û–Ø–ù–ù–´–ô –ü–û–ò–°–ö –õ–ò–¶ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–∏
            recognized_persons = self.face_recognizer.process_faces(
                raw_frame, self.frame_count, human_detected_in_frame
            )
            
            # –û—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ–º –ª–∏—Ü–∞ (–¥–∞–∂–µ –µ—Å–ª–∏ —á–µ–ª–æ–≤–µ–∫–∞ –Ω–µ—Ç, –Ω–æ –µ—Å—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã)
            display_frame = self.face_recognizer.draw_faces_smooth(display_frame, recognized_persons)

            # 3. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞
            if self.frame_count % 45 == 0:
                self.update_detection_status(human_detected_in_frame, raw_frame)

            # 4. –†–∞—Å—á–µ—Ç FPS
            current_time = time.time()
            if current_time - last_fps_calc >= 1.0:
                self.fps = fps_counter
                fps_counter = 0
                last_fps_calc = current_time

            # 5. –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–∞ —ç–∫—Ä–∞–Ω–µ
            self.add_info_text(display_frame, human_detected_in_frame, recognized_persons)

            # 6. –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            cv2.imshow('üöÅ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª–∏—Ü –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–∏', display_frame)

            self.frame_count += 1

            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

        self.cleanup()

    def add_info_text(self, frame, human_detected, recognized_persons):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –ë–ï–ó –ª–µ–≥–µ–Ω–¥—ã —Ü–≤–µ—Ç–æ–≤"""
        status_text = "HUMAN DETECTED" if human_detected else "HUMAN NOT DETECTED"
        color = (0, 255, 0) if human_detected else (0, 0, 255)

        cv2.putText(frame, status_text, (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)

        cv2.putText(frame, f"FPS: {self.fps}", (10, 60),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ª–∏—Ü (—Ç–æ–ª—å–∫–æ —Ü–∏—Ñ—Ä—ã)
        saved_count = self.face_recognizer.get_saved_faces_count()
        current_known = len([p for p in recognized_persons if p[0] != "Unknown"])
        
        saved_text = f"SAVED: {saved_count} | CURRENT: {current_known}"
        cv2.putText(frame, saved_text, (10, 90),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)
        
        # –£–ë–ò–†–ê–ï–ú –ª–µ–≥–µ–Ω–¥—É —Ü–≤–µ—Ç–æ–≤ –ø–æ–ª–Ω–æ—Å—Ç—å—é

    def cleanup(self):
        """–û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤"""
        self.camera.cleanup()
        self.pose_detector.cleanup()
        self.face_recognizer.cleanup()
        cv2.destroyAllWindows()
        print("‚úÖ –†–µ—Å—É—Ä—Å—ã –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω—ã")

if __name__ == "__main__":
    detector = HumanDetector()
    detector.show_camera_feed()